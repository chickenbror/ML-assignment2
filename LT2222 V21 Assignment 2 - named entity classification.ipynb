{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, you are going to build a classifier for named entities from the Groningen Meaning Bank corpus.  Named entity recognition (NER) takes noun phrases from a text and identifies whether they are persons, organizations, and so on.  You will be using the Groningen Meaning Bank named entity corpus available on mltgpu at `/scratch/lt2222-v21-resources/GMB_dataset.txt`.  In this version of the task, you will assume we know *that* something is a named entity, and instead use multi-class classification to identify its type.  So you will be doing named entity classification but *not* recognition.\n",
    "\n",
    "The data looks like this: \n",
    "\n",
    "```\n",
    "3996    182.0   Nicole  NNP     B-per\n",
    "3997    182.0   Ritchie NNP     I-per\n",
    "3998    182.0   is      VBZ     O\n",
    "3999    182.0   pregnant        JJ      O\n",
    "4000    182.0   .       .       O\n",
    "4001    183.0   Speaking        VBG     O\n",
    "4002    183.0   to      TO      O\n",
    "4003    183.0   ABC     NNP     B-org\n",
    "4004    183.0   News    NNP     I-org\n",
    "4005    183.0   interviewer     NN      O\n",
    "4006    183.0   Dianne  NNP     B-per\n",
    "4007    183.0   Sawyer  NNP     I-per\n",
    "4008    183.0   ,       ,       O\n",
    "4009    183.0   the     DT      O\n",
    "4010    183.0   25-year-old     JJ      O\n",
    "4011    183.0   co-star NN      O\n",
    "4012    183.0   of      IN      O\n",
    "4013    183.0   TV      NN      O\n",
    "4014    183.0   's      POS     O\n",
    "4015    183.0   The     DT      B-art\n",
    "4016    183.0   Simple  NNP     I-art\n",
    "4017    183.0   Life    NNP     I-art\n",
    "4018    183.0   said    VBD     O\n",
    "4019    183.0   she     PRP     O\n",
    "4020    183.0   is      VBZ     O\n",
    "4021    183.0   almost  RB      O\n",
    "4022    183.0   four    CD      O\n",
    "4023    183.0   months  NNS     O\n",
    "4024    183.0   along   IN      O\n",
    "4025    183.0   in      IN      O\n",
    "4026    183.0   her     PRP$    O\n",
    "4027    183.0   pregnancy       NN      O\n",
    "4028    183.0   .       .       O\n",
    "```\n",
    "\n",
    "The first column is the line number.  The second column is a sentence number (for some reason given as a float; ignore it).  The third column is the word.  The fourth column is a part of speech (POS) tag in Penn Treebank format.  The last column contains the named entity annotation. \n",
    "\n",
    "The annotation works like this.  Every `O` just means that the row does not represent a named entity.  `B-xyx` means the first word in a named entity with type `xyx`. `I-xyz` means the second and later words of an `xyz` entity, if there are any.  That means that every time there's a `B` or an `I`, there's a named entity.  \n",
    "\n",
    "The entity types in the corpus are `art`,\n",
    "`eve`,\n",
    "`geo`,\n",
    "`gpe`,\n",
    "`nat`,\n",
    "`org`,\n",
    "`per`,\n",
    "and `tim`\n",
    "\n",
    "Your task is the following.\n",
    "1. To preprocess the text (lowercase and lemmatize; punctuation can be preserved as it gets its own rows).\n",
    "2. To create instances from every from every identified named entity in the text with the type of the NE as the class, and a surrounding context of five words on either side as the features.  \n",
    "3. To generate vectors and split the instances into training and testing datasets at random.\n",
    "4. To train a support vector machine (via `sklearn.svm.LinearSVC`) for classifying the NERs.\n",
    "5. To evaluate the performance of the classifier.\n",
    "\n",
    "You will do this by modifying a separate file containing functions that will be called from this notebook as a module.  You can modify this notebook for testing purposes but please only submit the original.  You will document everything in Markdown in README.md and submit a GitHub repository URL.\n",
    "\n",
    "This assignment is due on **Tuesday, 2021 March 9 at 23:59**.  It has **25 points** and **7 bonus points**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a2\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmbfile = open('GMB_dataset.txt', \"r\")\n",
    "# (If running on MLT server)\n",
    "# gmbfile = open('/scratch/lt2222-v21-resources/GMB_dataset.txt', \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - preprocessing (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See step 1 above.  The data is coming to you as an unused file handle object.  You can return the data in any indexable form you like.  You can also choose to remove infrequent or uninformative words to reduce the size of the feature space. (Document this in README.md.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceNr</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>NEtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>family</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>soldier</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>kill</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>conflict</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>join</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>protester</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>who</td>\n",
       "      <td>WP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>carry</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>banner</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>such</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>slogan</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentenceNr       word  POS NEtag\n",
       "20           1       from   IN     O\n",
       "21           1       that   DT     O\n",
       "22           1    country   NN     O\n",
       "23           2     family  NNS     O\n",
       "24           2         of   IN     O\n",
       "25           2    soldier  NNS     O\n",
       "26           2       kill  VBN     O\n",
       "27           2         in   IN     O\n",
       "28           2        the   DT     O\n",
       "29           2   conflict   NN     O\n",
       "30           2       join  VBD     O\n",
       "31           2        the   DT     O\n",
       "32           2  protester  NNS     O\n",
       "33           2        who   WP     O\n",
       "34           2      carry  VBD     O\n",
       "35           2     banner  NNS     O\n",
       "36           2       with   IN     O\n",
       "37           2       such   JJ     O\n",
       "38           2     slogan  NNS     O\n",
       "39           2         as   IN     O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdata = a2.preprocess(gmbfile)\n",
    "gmbfile.close()\n",
    "inputdata[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Creating instances (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do step 2 above.  You will create a collection of Instance objects.  Remember to consider the case where the NE is at the beginning of a sentence or at the end, or close to either (you can create a special start token for that).  You can also start counting from before the `B` end of the NE mention and after the last `I` of the NE mention. That means that the instances should include things before and after the named entity mention, but not the named entity text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = a2.create_instances(inputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Class: gpe Features: ['<s1>', '<s2>', '<s3>', '<s4>', '<s5>', 'this', 'week', 'restart', 'part', 'of'],\n",
       " Class: geo Features: ['the', 'conversion', 'process', 'at', 'its', 'nuclear', 'plant', '</s1>', '</s2>', '</s3>'],\n",
       " Class: gpe Features: ['<s1>', '<s2>', '<s3>', '<s4>', '<s5>', 'official', 'say', 'they', 'expect', 'to'],\n",
       " Class: tim Features: ['sensitive', 'part', 'of', 'the', 'plant', 'after', 'an', 'iaea', 'surveillance', 'system'],\n",
       " Class: org Features: ['the', 'plant', 'wednesday', 'after', 'an', 'surveillance', 'system', 'begin', 'function', '</s1>'],\n",
       " Class: org Features: ['<s2>', '<s3>', '<s4>', '<s5>', 'The', 'surveillance', 'system', 'begin', 'function', '</s1>'],\n",
       " Class: gpe Features: ['<s5>', 'The', 'european', 'union', 'with', 'backing', 'have', 'threaten', 'to', 'refer'],\n",
       " Class: gpe Features: ['backing', 'have', 'threaten', 'to', 'refer', 'to', 'the', 'u.n.', 'security', 'council'],\n",
       " Class: org Features: ['to', 'refer', 'iran', 'to', 'the', 'to', 'the', 'u.n.', 'security', 'council'],\n",
       " Class: gpe Features: ['impose', 'sanction', 'if', 'it', 'find', 'have', 'violate', 'the', 'nuclear', 'non-proliferation'],\n",
       " Class: art Features: ['find', 'tehran', 'have', 'violate', 'the', 'have', 'violate', 'the', 'nuclear', 'non-proliferation'],\n",
       " Class: gpe Features: ['<s1>', '<s2>', '<s3>', '<s4>', '<s5>', \"'s\", 'new', 'president', 'mahmoud', 'ahmadinejad'],\n",
       " Class: per Features: ['<s4>', '<s5>', 'iran', \"'s\", 'new', \"'s\", 'new', 'president', 'mahmoud', 'ahmadinejad'],\n",
       " Class: tim Features: ['new', 'president', 'mahmoud', 'ahmadinejad', 'say', 'that', 'european', 'incentive', 'aim', 'at'],\n",
       " Class: gpe Features: ['mahmoud', 'ahmadinejad', 'say', 'tuesday', 'that', 'incentive', 'aim', 'at', 'persuade', 'iran'],\n",
       " Class: gpe Features: ['<s1>', '<s2>', '<s3>', '<s4>', '<s5>', \"'s\", 'new', 'president', 'mahmoud', 'ahmadinejad'],\n",
       " Class: gpe Features: ['be', 'an', 'insult', 'to', 'the', 'nation', '</s1>', '</s2>', '</s3>', '</s4>'],\n",
       " Class: gpe Features: ['<s2>', '<s3>', '<s4>', '<s5>', 'Two', 'and', 'four', 'nigerian', 'oil', 'worker'],\n",
       " Class: gpe Features: ['<s5>', 'Two', 'german', 'and', 'four', 'oil', 'worker', 'be', 'kidnap', 'by'],\n",
       " Class: geo Features: ['raid', 'on', 'a', 'boat', 'in', \"'s\", 'southern', 'oil-rich', 'delta', 'region']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Creating the table and splitting (10 points)\n",
    "\n",
    "Here you're going to write the functions that create a data table with \"document\" vectors representing each instance and split the table into training and testing sets and random with an 80%/20% train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NE_class</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.29184898987871394, -0.22289236295392845, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>geo</td>\n",
       "      <td>[0.1574744333056034, 0.14620880871082068, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.4009647553791204, -0.35883375703800696, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tim</td>\n",
       "      <td>[0.04316814481269096, 0.012291577274903483, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>org</td>\n",
       "      <td>[0.06821698262936284, 0.04101560676950414, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>org</td>\n",
       "      <td>[0.24514571016546235, -0.1294805791229831, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.09509039751821673, -0.061969373219631536, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.06741957692589423, -0.014630341345356464, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>org</td>\n",
       "      <td>[0.09001055701714501, 0.00776316702460329, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.042546286855863466, -0.02009004152557714, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>art</td>\n",
       "      <td>[0.06053796160480349, -0.023316811899646933, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.3168000103265534, -0.2764988253530417, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>per</td>\n",
       "      <td>[0.1296441987305433, -0.09742015310239115, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tim</td>\n",
       "      <td>[0.04404671204822383, -0.03052825649056066, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.03365237668704663, -0.025925054178576892, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.3168000103265534, -0.2764988253530417, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.2904030848360491, 0.25206971521376964, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.19376536622303667, -0.15782466160331135, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gpe</td>\n",
       "      <td>[0.08092262540338038, -0.04028566213833127, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>geo</td>\n",
       "      <td>[0.06069580266796713, 0.017918695454886936, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NE_class                                             vector\n",
       "20      gpe  [0.29184898987871394, -0.22289236295392845, -0...\n",
       "21      geo  [0.1574744333056034, 0.14620880871082068, 0.03...\n",
       "22      gpe  [0.4009647553791204, -0.35883375703800696, -0....\n",
       "23      tim  [0.04316814481269096, 0.012291577274903483, 0....\n",
       "24      org  [0.06821698262936284, 0.04101560676950414, 0.0...\n",
       "25      org  [0.24514571016546235, -0.1294805791229831, -0....\n",
       "26      gpe  [0.09509039751821673, -0.061969373219631536, 0...\n",
       "27      gpe  [0.06741957692589423, -0.014630341345356464, 0...\n",
       "28      org  [0.09001055701714501, 0.00776316702460329, 0.2...\n",
       "29      gpe  [0.042546286855863466, -0.02009004152557714, 0...\n",
       "30      art  [0.06053796160480349, -0.023316811899646933, 0...\n",
       "31      gpe  [0.3168000103265534, -0.2764988253530417, -0.0...\n",
       "32      per  [0.1296441987305433, -0.09742015310239115, 0.0...\n",
       "33      tim  [0.04404671204822383, -0.03052825649056066, 0....\n",
       "34      gpe  [0.03365237668704663, -0.025925054178576892, 0...\n",
       "35      gpe  [0.3168000103265534, -0.2764988253530417, -0.0...\n",
       "36      gpe  [0.2904030848360491, 0.25206971521376964, 0.09...\n",
       "37      gpe  [0.19376536622303667, -0.15782466160331135, -0...\n",
       "38      gpe  [0.08092262540338038, -0.04028566213833127, 0....\n",
       "39      geo  [0.06069580266796713, 0.017918695454886936, 0...."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf = a2.create_table(instances)\n",
    "bigdf[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.15686623e-01,  9.13556327e-02,  6.21339887e-02, ...,\n",
       "         -1.69677231e-03,  4.10390243e-03,  2.30264464e-03],\n",
       "        [ 6.68462054e-02,  2.46829473e-02,  1.74062872e-01, ...,\n",
       "          1.71420470e-03,  4.85696676e-03, -1.34390771e-03],\n",
       "        [ 7.17889936e-02, -5.28522162e-04,  1.74671800e-01, ...,\n",
       "         -2.62026663e-03,  3.10533137e-03,  9.83691479e-03],\n",
       "        ...,\n",
       "        [ 8.06187604e-02,  1.95192696e-02,  2.10544327e-01, ...,\n",
       "          5.64462698e-03,  2.42535396e-04, -3.71737121e-03],\n",
       "        [ 9.09462190e-02, -1.11156527e-02,  2.21790052e-01, ...,\n",
       "          1.24428169e-04,  2.61769994e-04,  4.23292144e-03],\n",
       "        [ 6.38486540e-02, -1.91450092e-02,  1.28403265e-01, ...,\n",
       "         -1.45546346e-03,  2.93120717e-03, -1.84162575e-03]]),\n",
       " 566     per\n",
       " 183     geo\n",
       " 2130    eve\n",
       " 5776    org\n",
       " 1706    gpe\n",
       "        ... \n",
       " 6728    per\n",
       " 1794    per\n",
       " 3409    geo\n",
       " 5862    gpe\n",
       " 4026    geo\n",
       " Name: NE_class, Length: 5538, dtype: object,\n",
       " array([[ 2.60832760e-02,  5.72399289e-04,  6.51854812e-02, ...,\n",
       "         -4.95396785e-03, -5.41247050e-03, -4.47210811e-03],\n",
       "        [ 6.48928753e-02,  1.11487600e-02,  1.63034759e-01, ...,\n",
       "          1.11666642e-03,  5.07569626e-03, -1.98973474e-03],\n",
       "        [ 2.42712813e-01, -1.79495928e-01, -7.28888177e-03, ...,\n",
       "         -7.57759568e-03,  4.31222843e-03,  2.74227741e-03],\n",
       "        ...,\n",
       "        [ 1.82024633e-02,  1.42542793e-03,  3.38650313e-02, ...,\n",
       "          4.45085895e-03, -2.63332857e-03,  1.80171136e-04],\n",
       "        [ 5.04351912e-02, -3.29300727e-02,  8.51691540e-02, ...,\n",
       "         -9.58361128e-03, -2.80234121e-03,  7.03550030e-03],\n",
       "        [ 2.88417727e-01,  3.19069852e-01, -9.86644139e-03, ...,\n",
       "         -5.09367385e-04,  9.23317800e-04,  3.28590010e-03]]),\n",
       " 3       per\n",
       " 4       geo\n",
       " 12      geo\n",
       " 21      geo\n",
       " 29      gpe\n",
       "        ... \n",
       " 6902    org\n",
       " 6911    org\n",
       " 6915    per\n",
       " 6916    geo\n",
       " 6920    per\n",
       " Name: NE_class, Length: 1384, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = a2.ttsplit(bigdf)\n",
    "\n",
    "# X and y mean feature matrix and class respectively.\n",
    "train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999422132331696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y) / (len(test_y) + len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999422132331696"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X) / (len(test_X) + len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geo'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_y[0] # *key error if 0th row not in test dada\n",
    "zeroth = test_y[0] if 0 in test_y else train_y[0]\n",
    "zeroth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Training the model (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part you won't do yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train_X, train_y)\n",
    "train_predictions = model.predict(train_X)\n",
    "test_predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['per', 'geo', 'eve', ..., 'geo', 'gpe', 'geo'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566     per\n",
       "183     geo\n",
       "2130    eve\n",
       "5776    org\n",
       "1706    gpe\n",
       "       ... \n",
       "6728    per\n",
       "1794    per\n",
       "3409    geo\n",
       "5862    gpe\n",
       "4026    geo\n",
       "Name: NE_class, Length: 5538, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['geo', 'gpe', 'tim', ..., 'per', 'org', 'gpe'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       per\n",
       "4       geo\n",
       "12      geo\n",
       "21      geo\n",
       "29      gpe\n",
       "       ... \n",
       "6902    org\n",
       "6911    org\n",
       "6915    per\n",
       "6916    geo\n",
       "6920    per\n",
       "Name: NE_class, Length: 1384, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Evaluation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate for yourself what a \"confusion matrix\".  Then implement a function that takes the data and produces a confusion matrix in any readable form that allows us to compare the performance of the model by class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       per\n",
       "4       geo\n",
       "12      geo\n",
       "21      geo\n",
       "29      gpe\n",
       "       ... \n",
       "6902    org\n",
       "6911    org\n",
       "6915    per\n",
       "6916    geo\n",
       "6920    per\n",
       "Name: NE_class, Length: 1384, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y #1384 'gold' NE classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['geo', 'gpe', 'tim', ..., 'per', 'org', 'gpe'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions #1384 preducted NE classes\n",
    "\n",
    "# confusion matrix: N*N ie 8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>eve</th>\n",
       "      <th>geo</th>\n",
       "      <th>gpe</th>\n",
       "      <th>nat</th>\n",
       "      <th>org</th>\n",
       "      <th>per</th>\n",
       "      <th>tim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>44</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     art  eve  geo  gpe  nat  org  per  tim\n",
       "art    3    0    0    1    0    0    0    0\n",
       "eve    0    1    1    1    0    0    0    0\n",
       "geo    3    2  195   56    0   61   44   87\n",
       "gpe    2    1   41   86    0   36   40   19\n",
       "nat    0    0    0    0    2    0    0    0\n",
       "org    3    0   54   35    1   78   31   23\n",
       "per    0    0   37   44    0   46   98   26\n",
       "tim    1    5   59   21    1   32   24   83"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.confusion_matrix(test_y, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>eve</th>\n",
       "      <th>geo</th>\n",
       "      <th>gpe</th>\n",
       "      <th>nat</th>\n",
       "      <th>org</th>\n",
       "      <th>per</th>\n",
       "      <th>tim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1506</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>803</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>752</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     art  eve   geo  gpe  nat  org  per  tim\n",
       "art   39    0     0    0    0    0    1    0\n",
       "eve    0   28     0    1    0    0    0    0\n",
       "geo    0    2  1506   72    2   80   47   65\n",
       "gpe    0    0    50  807    0   38   35   17\n",
       "nat    0    0     0    0   14    0    0    0\n",
       "org    1    0    46   39    0  803   19   17\n",
       "per    1    5    38   49    0   42  752   20\n",
       "tim    0    1    43   18    0   21   16  803"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.confusion_matrix(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the matrix and describe your observations in README.md.  In particular, what do you notice about the predictions on the training data compared to those on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part A - Error analysis (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the weakest-performing classes in the confusion matrix (or any, if they all perform poorly to the same extent).  Find some examples in the test data on which the classifier classified incorrectly for those classes.  What do you think is the reason why those are hard?  Consider linguistic factors and statistical factors, if applicable.  Write your answer in README.md."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part B - Expanding the feature space (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the entire process above, but incorporate part-of-speech tag information into the feature vectors.  It's your choice as to how to do this, but document it in README.md.  Your new process should run from the single call below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing:Testing = 80.0%:19.999999999999996% \n",
      "Reduced dims: 3000-D \n",
      "\n",
      "\n",
      " Confusion matrix of TEST DATA:\n",
      "     art  eve  geo  gpe  nat  org  per  tim\n",
      "art    1    0    0    0    0    0    0    1\n",
      "eve    0    0    0    0    0    0    0    0\n",
      "geo    2    3  243   55    0   66   51   65\n",
      "gpe    2    1   47  100    0   44   37   24\n",
      "nat    0    0    0    0    0    0    0    0\n",
      "org    3    2   49   26    0   75   35   20\n",
      "per    0    1   39   34    0   31   91   16\n",
      "tim    4    4   39   24    2   28   22   97\n",
      "\n",
      " Confusion matrix of TRAINING DATA:\n",
      "     art  eve   geo  gpe  nat  org  per  tim\n",
      "art   38    0     0    0    0    0    0    0\n",
      "eve    0   26     0    0    0    0    0    0\n",
      "geo    1    4  1478   78    3   96   38   73\n",
      "gpe    0    0    49  808    0   45   18   27\n",
      "nat    0    0     0    0   14    0    0    0\n",
      "org    1    2    42   40    1  786   32   17\n",
      "per    0    1    37   42    0   43  763   21\n",
      "tim    1    1    47   23    0   23   20  799\n"
     ]
    }
   ],
   "source": [
    "a2.bonusb('GMB_dataset.txt', reduced_dims=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing:Testing = 80.0%:19.999999999999996% \n",
      "Reduced dims: 4000-D \n",
      "\n",
      "\n",
      " Confusion matrix of TEST DATA:\n",
      "     art  eve  geo  gpe  nat  org  per  tim\n",
      "art    2    0    0    1    0    0    0    0\n",
      "eve    0    0    3    0    0    0    0    0\n",
      "geo    8    3  220   57    3   70   41   67\n",
      "gpe    1    1   50   98    0   37   25   18\n",
      "nat    0    0    0    0    0    0    0    0\n",
      "org    2    2   50   38    1   75   33   24\n",
      "per    0    1   31   37    0   34  108   20\n",
      "tim    3    3   39   29    1   20   18  110\n",
      "\n",
      " Confusion matrix of TRAINING DATA:\n",
      "     art  eve   geo  gpe  nat  org  per  tim\n",
      "art   36    0     0    0    0    0    0    0\n",
      "eve    0   30     1    0    0    0    0    0\n",
      "geo    0    2  1516   66    3   81   42   65\n",
      "gpe    0    0    44  803    0   51   19   20\n",
      "nat    0    0     0    0   12    0    0    0\n",
      "org    0    0    41   31    0  801   26   16\n",
      "per    0    2    42   51    0   45  782   17\n",
      "tim    1    1    33   19    0   23   13  803\n"
     ]
    }
   ],
   "source": [
    "a2.bonusb('GMB_dataset.txt', reduced_dims=4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
